{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, Reshape, Flatten\n",
    "from keras import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "dir_path = sys.argv[1]\n",
    "\n",
    "headers = ['Date', 'Time', 'Global_active_power', 'Global_reactive_power',\n",
    "           'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2',\n",
    "           'Sub_metering_3']\n",
    "\n",
    "dtypes = {'Date':'str', 'Time':'str', 'Global_active_power':'float',\n",
    "          'Global_reactive_power': 'float', 'Voltage':'float',\n",
    "          'Global_intensity':'float', 'Sub_metering_1':'float',\n",
    "          'Sub_metering_2':'float', 'Sub_metering_3':'float'}\n",
    "\n",
    "# print(df.head)\n",
    "\n",
    "\n",
    "def parallel_map(data, func):\n",
    "    n_cores = cpu_count()\n",
    "    data_split = np.array_split(data, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    data = pd.concat(pool.map(func, data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data\n",
    "\n",
    "def parse(row):\n",
    "    row['DateTime'] = pd.to_datetime(row['DateTime'],format='%d/%m/%Y %H:%M:%S')\n",
    "    return row\n",
    "\n",
    "def series_to_supervised(data, window_size=1, horizon=1, inputs='all', targets='all'):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    \n",
    "    Arguments:\n",
    "        data: A pandas DataFrame containing the time series\n",
    "        (the index must be a DateTimeIndex).\n",
    "        window_size: Number of lagged observations as input.\n",
    "        horizon: Number of steps to forecast ahead.\n",
    "        inputs: A list of the columns of the dataframe to be lagged.\n",
    "        targets: A list of the columns of the dataframe to be forecasted.\n",
    "    \n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    if targets == 'all':\n",
    "        targets = data.columns\n",
    "    \n",
    "    if inputs == 'all':\n",
    "        inputs = data.columns\n",
    "\n",
    "    \n",
    "    result = DataFrame(index=df.index)\n",
    "    names = []\n",
    "    \n",
    "    # input sequence (t-w, ..., t-1)\n",
    "    for i in range(window_size, 0, -1):\n",
    "        result = pd.concat([result, data[inputs].shift(i)], axis=1)\n",
    "        names += [(f'{data[inputs].columns[j]}(t-{i})') for j in range(len(inputs))]\n",
    "    \n",
    "    # the input not shifted (t)\n",
    "    result = pd.concat([result, data.copy()], axis=1)\n",
    "    names += [(f'{column}(t)') for column in data.columns]\n",
    "    \n",
    "    # forecast (t+h)\n",
    "    for i in [horizon]:\n",
    "        result = pd.concat([result, data[targets].shift(-i)], axis=1)\n",
    "        names += [(f'{data[targets].columns[j]}(t+{i})') for j in range(len(targets))]\n",
    "    \n",
    "    # put it all together\n",
    "    result.columns = names\n",
    "\n",
    "    # drop rows with NaN values\n",
    "    result.dropna(inplace=True)\n",
    "    return result\n",
    "\n",
    "def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    m = len(df)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[:train_end]\n",
    "    validate = df.iloc[train_end:validate_end]\n",
    "    test = df.iloc[validate_end:]\n",
    "    return train, validate, test\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"household_power_consumption.txt\", sep=';',dtype=dtypes, na_values=['?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df['DateTime'] = df['Date'] + ' ' + df['Time']\n",
    "df = parallel_map(df, parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "df = df[[df.columns[-1]] + list(df.columns[:-1])]\n",
    "df.set_index('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df.index.hour\n",
    "df['day'] = df.index.day\n",
    "df['month'] = df.index.month\n",
    "df['day_of_week'] = df.index.dayofweek\n",
    "df['Rest_active_power'] = df['Global_active_power'] * 1000 / 60 - df['Sub_metering_1'] - df['Sub_metering_2'] - df['Sub_metering_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['Global_active_power', 'Global_reactive_power', 'Voltage',\n",
    "          'Global_intensity', 'Sub_metering_1', 'Sub_metering_2',\n",
    "          'Sub_metering_3', 'Rest_active_power']\n",
    "\n",
    "targets = ['Global_active_power']\n",
    "\n",
    "df_supervised = series_to_supervised(df, window_size=5, horizon=1, inputs=inputs, targets=targets)\n",
    "# df_supervised.head()\n",
    "\n",
    "train,validate, test = train_validate_test_split(df_supervised)\n",
    "print(type(train))\n",
    "print(train.shape)\n",
    "\n",
    "\n",
    "X_train = train.values[:, :-1]\n",
    "y_train = train.values[:, -1]\n",
    "\n",
    "X_validate = validate.values[:, :-1]\n",
    "y_validate = validate.values[:, -1]\n",
    "\n",
    "X_test = test.values[:, :-1]\n",
    "y_test = test.values[:, -1]\n",
    "\n",
    "print(\"Here\")\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validate = scaler.transform(X_validate)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_validate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
